{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mustafabozkaya/Generative_AI/blob/master/Duffision/Duffision_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1\n",
        "### Your first day at your new job ðŸ‘©â€ðŸ’»ðŸ‘¨â€ðŸ’»\n",
        "\n",
        "You are starting a new job as a junior software developer in an IT company.\n",
        "\n",
        "The companyâ€™s HR department asks you to fill out a form, so you start by assigning your personal information to corresponding variables.\n",
        "\n",
        "ðŸ“Œ Create a variable for your name, surname, age, ID number, place of residence, to specify if you have active health insurance or not, and lastly one for specifying your nationality.\n"
      ],
      "metadata": {
        "id": "VMuUK0ap_bRD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPLhhc2Sp-D0"
      },
      "outputs": [],
      "source": [
        "#Please assign your personal information to variables\n",
        "my_name=\"Mustafa\"\n",
        "my_surname=\"BOZKAYA\"\n",
        "my_age=30\n",
        "ID_number=369258147\n",
        "my_nationality=\"Kurdish\"\n",
        "where_i_live=\"Gaziantep\"\n",
        "health_insurance=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dome272/Diffusion-Models-pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWK76KBZK3E8",
        "outputId": "8ed3b838-b12c-428a-b41c-882c9849a0bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Diffusion-Models-pytorch'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Total 47 (delta 0), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Receiving objects: 100% (47/47), 20.88 KiB | 890.00 KiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikZySedULAFH",
        "outputId": "67ce7e20-d34a-4dd7-9763-cface90f4361"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mDiffusion-Models-pytorch\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Diffusion-Models-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGi0U0qcMAzK",
        "outputId": "b931b65c-eb95-4344-8052-a0f2d344f1ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Diffusion-Models-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyCAiDhVMICG",
        "outputId": "1d893dd6-b8d9-4e1e-8180-3f111296ea7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ddpm_conditional.py  LICENSE     noising_test.py  utils.py\n",
            "ddpm.py              modules.py  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch import optim\n",
        "from utils import *\n",
        "from modules import UNet\n",
        "import logging\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")\n",
        "\n",
        "\n",
        "class Diffusion:\n",
        "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\"):\n",
        "        self.noise_steps = noise_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.img_size = img_size\n",
        "        self.device = device\n",
        "\n",
        "        self.beta = self.prepare_noise_schedule().to(device)\n",
        "        self.alpha = 1. - self.beta\n",
        "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
        "\n",
        "    def prepare_noise_schedule(self):\n",
        "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
        "\n",
        "    def noise_images(self, x, t):\n",
        "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
        "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
        "        Æ = torch.randn_like(x)\n",
        "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Æ, Æ\n",
        "\n",
        "    def sample_timesteps(self, n):\n",
        "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
        "\n",
        "    def sample(self, model, n):\n",
        "        logging.info(f\"Sampling {n} new images....\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x = torch.randn((n, 3, self.img_size, self.img_size)).to(self.device)\n",
        "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
        "                t = (torch.ones(n) * i).long().to(self.device)\n",
        "                predicted_noise = model(x, t)\n",
        "                alpha = self.alpha[t][:, None, None, None]\n",
        "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
        "                beta = self.beta[t][:, None, None, None]\n",
        "                if i > 1:\n",
        "                    noise = torch.randn_like(x)\n",
        "                else:\n",
        "                    noise = torch.zeros_like(x)\n",
        "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
        "        model.train()\n",
        "        x = (x.clamp(-1, 1) + 1) / 2\n",
        "        x = (x * 255).type(torch.uint8)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    setup_logging(args.run_name)\n",
        "    device = args.device\n",
        "    dataloader = get_data(args)\n",
        "    model = UNet().to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
        "    mse = nn.MSELoss()\n",
        "    diffusion = Diffusion(img_size=args.image_size, device=device)\n",
        "    logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n",
        "    l = len(dataloader)\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        logging.info(f\"Starting epoch {epoch}:\")\n",
        "        pbar = tqdm(dataloader)\n",
        "        for i, (images, _) in enumerate(pbar):\n",
        "            images = images.to(device)\n",
        "            t = diffusion.sample_timesteps(images.shape[0]).to(device)\n",
        "            x_t, noise = diffusion.noise_images(images, t)\n",
        "            predicted_noise = model(x_t, t)\n",
        "            loss = mse(noise, predicted_noise)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.set_postfix(MSE=loss.item())\n",
        "            logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
        "\n",
        "        sampled_images = diffusion.sample(model, n=images.shape[0])\n",
        "        save_images(sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}.jpg\"))\n",
        "        torch.save(model.state_dict(), os.path.join(\"models\", args.run_name, f\"ckpt.pt\"))\n",
        "\n",
        "\n",
        "def launch():\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser()\n",
        "    args = parser.parse_args()\n",
        "    args.run_name = \"DDPM_Uncondtional\"\n",
        "    args.epochs = 500\n",
        "    args.batch_size = 12\n",
        "    args.image_size = 64\n",
        "    args.dataset_path = r\"C:\\Users\\dome\\datasets\\landscape_img_folder\"\n",
        "    args.device = \"cuda\"\n",
        "    args.lr = 3e-4\n",
        "    train(args)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    launch()\n",
        "    # device = \"cuda\"\n",
        "    # model = UNet().to(device)\n",
        "    # ckpt = torch.load(\"./working/orig/ckpt.pt\")\n",
        "    # model.load_state_dict(ckpt)\n",
        "    # diffusion = Diffusion(img_size=64, device=device)\n",
        "    # x = diffusion.sample(model, 8)\n",
        "    # print(x.shape)\n",
        "    # plt.figure(figsize=(32, 32))\n",
        "    # plt.imshow(torch.cat([\n",
        "    #     torch.cat([i for i in x.cpu()], dim=-1),\n",
        "    # ], dim=-2).permute(1, 2, 0).cpu())\n",
        "    # plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "k_lcQCgUJ5m4",
        "outputId": "43362672-08d7-4423-e4af-4e0917c72b03"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c70385e8efff>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.linspace(1e-4, 0.02, 10).to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "CwUvhBM9Mz_f",
        "outputId": "07b0bbdc-f29c-4817-a3d8-7beda45c9ed2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7e7d70ca6d2c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "beta = self.prepare_noise_schedule().to(device)\n",
        "alpha = 1. - self.beta\n",
        "alpha_hat = torch.cumprod(self.alpha, dim=0)"
      ],
      "metadata": {
        "id": "UW_ptr2PNr4a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "c5914ae3790566b9cd0e984a9bdda42a29da8adf046b5ac0173e0d37aacf3dab"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}